%
% Second part of the main code
%
\subsection{Fixed effects}
The mixed effects Cox model is written as
\begin{eqnarray*}
  \lambda(t) &=& \lambda_0(t) e^{X \beta + Z b}\\
  b &\sim& N(0, \Sigma(\theta))
\end{eqnarray*}
The coefficient vectors $\beta$ and $b$ correspond the the
fixed and random effects, respectively,
with $X$ and $Z$ as the respective design matrices.

It is now time to build $X$, the design matrix for the fixed effects.
The
of the model. 
We first separate the model into random and fixed effects terms
using the [[formula1]] function.
As an argument it takes the model formula as given by the user
and it returns a list containing the fixed and random parts of
the formula, respectively.
If any vertical bars remain in the fixed result, then there is
a problem with the supplied formula, 
usually a random effects term that was missing the enclosing
parentheses.
<<decompose-formula>>=
    flist <- formula1(formula)
    if (hasAbar(flist$fixed))
        stop("Invalid formula: a '|' outside of a valid random effects term")

    special <- c("strata", "cluster")
    Terms <- terms(flist$fixed, special)
    attr(Terms,"intercept")<- 1  #Cox model always has \Lambda_0
    strats <- attr(Terms, "specials")$strata
    cluster<- attr(Terms, "specials")$cluster
    if (length(cluster)) {
        stop ("A cluster() statement is invalid in coxme")
        }
    if (length(strats)) {
        temp <- untangle.specials(Terms, 'strata', 1)
        dropx <- c(dropx, temp$terms)
        if (length(temp$vars)==1) strata.keep <- m[[temp$vars]]
        else strata.keep <- strata(m[,temp$vars], shortlabel=T)
        strats <- as.numeric(strata.keep)
        X <- model.matrix(Terms[-temp$terms], m)[,-1,drop=F]
        }
    else X <- model.matrix(Terms, m)[,-1,drop=F]


@ 
The key tools for building the matrix are the [[terms]] and [[model.matrix]]
functions, which are common to all S modeling routines.
The [[terms]] function takes a standard formula, and returns an object that
is used for later processing.
The [[specials]] argument asks the function to note any calls to
\emph{cluster} or \emph{strata} in the formula, this makes it possible
for us to pull out those terms for special processing.

The \emph{cluster()} function is used in [[coxph]] to
obtain a generalized estimating equation (GEE) type of variance estimate.
Random effects and GEE are two different ways to approach
correlated outcomes, but they cannot be mixed.  
Thus such a term is invalid in a [[coxme]] model.

In a Cox model the baseline hazard $\lambda_0$ plays the role of an
intercept, but the $X$ matrix does not explicitly contain an intercept.
Nevertheless, contrasts terms, such as the dummy variable codings for
factors, need to be formed as though there were an intercept term.
We thus mark the model as containing an intercept column by setting the
intercept attribute of [[terms]] (and completely ignore any ``-1'' that
the user put into the model) before calling [[model.matrix]].
After then remove the unneeded intercept column from the returned
matrix.  
The resulting $X$ matrix might have only one column; the [[drop=F]]
option causes it to remain a matix and not become a vector.
If there are only random effects in the model, $X$ could even have 0
columns.

If there are strata, they are removed from the model formula
before forming the X matrix, since strata effect only the
baseline hazard.
The variable [[strata.keep]] retains the strata levels as specified by
the user.
The variable [[strats]] has values of 1,2, \ldots and
is simpler for the underlying C code to deal with.

\subsection{Random effects}
Creating the random effects components is more complicated than the 
fixed effects.
\begin{itemize}
  \item We need to create both the $Z$ matrix and $\Sigma$.
  \item The actual form of $Z$ depends on the type of random
    effect: a familial correlation will be different than an compound
    symmetry.  There are many possible correlation structures.
  \item If there are multiple random terms, each creates a block of columns
    in $Z$ and block of values in $\Sigma$.
  \item For efficiency, some or all of the class variables in $Z$ may be
    represented in compressed form.  
    Such variables are stored in a matrix $F$ which has a single column 
    for each class variable, with integer
    values of 1,2, \ldots. $Z$ will contain the remaining
    columns.
\end{itemize}
The basic flow of the routine is to process the random terms one at a time.
The [[varlist]] component describes a variance family for each term; and
we do two calls for each.
The first call is to the \emph{init} member of the family, giving it the
$G$ containing the grouping variables along with the number of columns in
$C$ and whether or not the left hand side contained an intercept.
It returns corresponding columns of $F$ and $Z$, a named vector of parameters
$\theta$ containing the set of variance parameters to be optimized, and
a parameter list which will be used in the [[coxme.fit]] routine.
 
Given the names of the $\theta$ parameters, the routine is now able to match
any elements of the [[vinit]] and [[variance]] arguments to it, in order
to set either initial values or fixed values for them.
The second call is to the \emph{iparm} member of the family, which then sets
initial values for the remainder of the parameters, as well as possibly
transforming some or all of them to a different scale.  
Such a transformation is private to the variance family function.

The [[formula2]] function is desribed later; it is responsible for 
further separating the components of each random terms for us: 
whether the left hand side has
an intercept, any other variables on the left, grouping variables, and
optional interaction.

Our first action is to check out the [[varlist]] option.  This is 
complicated by the fact that users can give a partial one, or none,
allowing the default to be used for other elements.
Each element of the varlist should be one of the generating functions
for a [[coxvar]] object.
If it is not, then the arguments are 
turned into a call to [[coxvarMlist]], which
handles lists that contain a mixture of matrices and/or matrix
generating functions.
This latter is to maintain backwards compatability 
with the first coxme code, which allowed only that form.
Of course one problem with this is that a simple typing mistake will
lead to an error from within the [[coxvarMlist]] routine, which may
be more confusing.
<<build-control-structures>>=
nrandom <- length(flist$random)
if (nrandom ==0) stop("No random effects terms found")
<<get-cmat>>
<<get-groups>>
<<make-vinit>>
<<newzmat>>
vparms <- vector('list', nrandom)
fname <- zname <- thetalist <- vparms
if (missing(varlist)) {
    varlist <- vector('list', nrandom)
    for (i in 1:nrandom) varlist[[i]] <- coxvarFull #default
    }
else {
    if (nrandom==1) { # allow a single non-list
        if (!is.list(varlist)) varlist <- list(varlist)
        }
    if (length(varlist) != nrandom) stop ("Wrong length for varlist")
    for (i in 1:length(varlist)) {
        if (!inherits(varlist[[i]], 'coxvar'))
            varlist[[i]] <- coxvarMlist(varlist[[i]])
        }
    }
@ 
At this point we have a valid [[varlist]] object, with is a list with
one element per random term, each element is an object of class `coxvar'.
The current options for these elements are
\begin{description}
\item [coxvarFull] All variance/covariance terms between random elements are
present.  For instance the term [[(1+age | group)]] specifies a random
intercept and slope.  The variance structure will have 3 parameters: the variance of the intercepts, the
variance of the slopes, and their covariance.
\item [coxvarMlist]  The variance is assumed to be of the form
$\sigma_1^2 A_1 + \sigma_2^2 A_2 + \ldots$ for a set of fixed matrices
$A_1, A_2, \ldots$.  This is commonly used in genetic studies where $A_1$
would be the kinship matrix for a set of subjects/families and $A_2$ might
be the identity-by-descent (IBD) matrix for a particular locus.
For backwards compatability a naked list of matrices may be given, and they
are packaged into a call to [[coxvarMlist]]; however this does not allow a user
to modify certain options.
\end{description}

Now we proceed through the list one element at a time, and do the necessary
setup. The variables [[nfac]] and [[nslope]] contain the number of columns
of [[fmat]] and [[zmat]] contributed by each term. 

<<build-control-structures>>=    
fmat <- zmat <- NULL
nfac <- nslope <- integer(nrandom)
stemp <- sparse
for (i in 1:nrandom) {
    f2 <- formula2(flist$random[[i]])
    vfun <- varlist[[i]]
    if (!is.null(f2$interaction)) stop("Interactions not yet written")

    cmat <- getcmat(f2$fixed, m)
    groups <- getgroups(f2$group, m)
    init <- vfun$init(vinit[[i]], variance[[i]], intercept=f2$intercept, 
                        groups, cmat, stemp)
    vparms[[i]] <- init$parms

    if (f2$intercept) {
        if (!is.matrix(init$F) || nrow(init$F) !=n) 
            stop("Invalid result from coxvar function for F")
        nfac[i] <- ncol(init$F)
        fmat <- cbind(fmat, init$F)
        if (stemp[2] < 1) {
            nsparse <- init$sparse
            stemp[2] <- 1
            }
        }
    if (!is.null(cmat)) {
        temp <- newzmat(cmat, fmat)
        zmat <- cbind(zmat, temp)
        nslope[i] <- ncol(temp)
        }
} 
if (nsparse>0 & nfac[1]==0) { #must reorder
    # Fix this later
    stop("Only the first random term can be sparse")
    }
@ 
The matrix $F$ holds the columns associated with intercept terms,
so has columns added only if the new random terms has a 1 on the
left side of the formula.
It is also (at present) the only case in which sparse computation is
known to be valid.  However, only one term can be sparse:  once one
has been found the second element of stemp is set to 1 to ensure no
others.

 The underlying C programs can't deal with holes in a factor variable.
That is, every column of fmat must be integers, with minimum 1 and no
gaps.  We ensure this, at the same time remembering the number of
unique levels in each, which is what will determines the number of
random coefficients $b$.
<<build-control-structuer>>=
if (is.null(fmat)) nfac.nlevel <- NULL
else {
    nfac.nlevel <- integer(ncol(fmat))
    for (i in 1:ncol(fmat)) {
        if (any(fmat[,i] != as.integer(fmat[,i]))) 
            stop("Invalid code for group")
        temp <- sort(unique(fmat[,i]))
        if (temp != 1:(max(temp)))
            stop ("Missing code in group")
        nfac.nlevel[i] <- max(temp)
        }
    }


Now to fill in a few blanks from the above discussion.
First the vector (list) of initial values [[vinit]] or fixed variance
values [[variance]] given by the user may not be complete.
We want to expand them out to to lists, and have the same length as 
[[varlist]].
In the case of multiple terms, we allow the user to specify a subset of
them, using the names of the grouping variables.  If names are
not used (or are not unique) things match in order.
If there is a single random term we allow a numeric vector.
<<make-vinit>>=
if (missing(vinit)) vinit <- vector('list', nrandom)
else {
    if (nrandom==1 && is.numeric(vinit)) vinit <- list(vinit)
    if (!is.list(vinit)) stop("Invalid value for `vinit` parameter")
    if (length(vinit) > nrandom) stop ("Invalid length for vinit")
    if (!all(sapply(vinit, is.numeric))) 
        stop("Vinit must contain numeric values") 
    
    if (length(vinit) < nrandom) 
        vinit <- c(vinit, vector('list', nrandom - length(vinit)))
                   
    tname <- names(vinit)
    if (!is.null(tname)) {
        temp <- pmatch(tname, names(flist$random), nomatch=0)
        temp <- c(temp, (1:nrandom)[-temp])
        vinit <- vinit[temp]
        }
  }

if (missing(variance)) variance <- vector('list', nrandom)
else {
    if (nrandom==1 && is.numeric(variance)) variance <- list(variance)
    if (!is.list(variance)) stop("Invalid value for `variance` parameter")
    if (length(variance) > nrandom) stop ("Invalid length for variance")
    if (!all(sapply(variance, is.numeric))) 
        stop("Variance must contain numeric values") 
    
    if (length(variance) < nrandom) 
        variance <- c(variance, vector('list', nrandom - length(variance)))
                   
    tname <- names(variance)
    if (!is.null(tname)) {
        temp <- pmatch(tname, names(flist$random), nomatch=0)
        temp <- c(temp, (1:nrandom)[-temp])
        variance <- variance[temp]
        }
  }
@ 

The actual computation of the model is done in [[coxme.fit]].  
This was separated from the main routine partly to leave the code in
managable chunks.
<<call-computation-routine>>=
browser()
fit <- coxme.fit(X, Y, strats, offset, init, control, weights=weights,
                 ties=ties, row.names(m), refine.n,
                 varlist, vparm, thetalist, fixed, 
                 fmat, zmat, refine.n)
@ 

Then we finish up be packaging up the results for a user.
The first few lines are the case where a fatal error occured, in which
case the result contains only the failure line.
(Is this needed?)
<<finish-up>>=
if (is.character(fit)) {
    fit <- list(fail=fit)
    oldClass(fit) <- 'coxme'
    return(fit)
    }
@ 
Now add labels to the fixed coefficients and to the frailty terms.
The [[coefficients]] portion of the returned object conttains the
values for $\hat \beta$ (fixed) and for the variances $\hat \theta$.
The [[frail]] component contains the values for $\hat b$.
<<finish-up>>=
time2 <- proc.time()
fcoef <- fit$coefficients$fixed
nvar <- length(fcoef)
if (length(fcoef)>0 && any(is.na(fcoef))) {
    vars <- (1:length(fcoef))[is.na(fcoef)]
    msg <-paste("X matrix deemed to be singular; variable",
                    paste(vars, collapse=" "))
    if (singular.ok) warning(msg)
    else             stop(msg)
    }
if (length(fcoef) >0) {
    names(fcoef) <- dimnames(X)[[2]]
    fit$coefficients <- list(fixed=fcoef, random=fit$coeff$random)
    }

if (ncluster==1) {
    names(fit$frail) <- dimnames(varlist[[1]][[1]])[[1]]
    flinear <- fit$frail[kindex]
    }
else {
    ftemp <- vector('list', ncluster)
    j <- 0
    flinear <- 0
    for (i in 1:ncluster) {
        tname <- dimnames(varlist[[i]][[1]])[[1]]
        nf <- length(tname)
        temp <- fit$frail[j + 1:nf]
        flinear <- flinear + temp[kindex[,i]]
        names(temp) <- tname
        ftemp[[i]]<- temp
        j <- j+nf
        }
    names(ftemp) <- gnames
    fit$frail <- ftemp
    }

if (nvar ==0) fit$linear.predictor <- as.vector(flinear)
else fit$linear.predictor <- as.vector(flinear + c(X %*% fit$coef$fixed))
@ 
Last fill in a set of miscellaneous members of the structure
<<finish-up>>=
fit$n <- nrow(Y)
fit$terms <- Terms
fit$assign <- attr(X, 'assign')

na.action <- attr(m, "na.action")
if (length(na.action)) fit$na.action <- na.action
if (x)  {
    fit$x <- X
    if (length(strats)) fit$strata <- strata.keep
    }
if (y)     fit$y <- Y
if (!is.null(weights) && any(weights!=1)) fit$weights <- weights

time3 <- proc.time()
timeused <- c((time1[1]+ time1[2]) - (time0[1] + time0[2]), fit$timeused,
              (time3[1]+ time3[2]) - (time2[1] + time2[2]))
timeused <- c(sum(timeused), timeused)
names(timeused) <- c("Total", "setup", "fit1", "fit2", "fit3", "finish")
fit$timeused <- timeused

fit$formula <- as.vector(attr(Terms, "formula"))
fit$call <- Call
fit$ties <- ties
fit$kindex <- kindex
names(fit$loglik) <- c("NULL", "Integrated", "Penalized")
oldClass(fit) <- 'coxme'
fit
}
@ 

\subsection{Creating the $C$ and $F$ matrices}
To create the columns for $F$ there are 3 steps.
First we get the variables from the data frame, treating each of them
as a factor.  This is then submitted to the
appropriate coxvar family function, which
creates the integer matrix of codes that are actually used.

The allnames function will be given a single right-hand side of a
single random effects term, so it does not need to be fancy.
(Question - is there  a standard R function for this?)
<<get-groups>>=
allnames <- function(x){
    if (is.call(x)) {
        if (length(x) == 3) return( c(allnames(x[[2]]), allnames(x[[3]])))
        else return(allnames(x[[2]]))
      }
    if (is.name(x)) as.character(x) else NULL
  }

getgroups <- function(x, mf) {
    varname <- allnames(x)
    if (is.null(varname)) return(NULL)  # a shrinkage effect like (x1+x2 | 1)
    data.frame(lapply(mf[varname], as.factor))
    }
@ 
A common task for the variance functions is to exand [[school/teacher]]
type terms into a set of unique levels, i.e., to find all the unique
combinations of the two variables.  Teacher 1 in school 1 is not the same
person as teacher 1 in school 2.
We can't use the usual processing functions such as [[model.matrix]]
to create the nesting variables, since it also expands the factors
into multiple columns of a matrix.  (This is how [[lmer]] does it.)
We will use the [[strata]] function from the standard survival library.
<<expand.nested>>=
expand.nested <- function(x) {
    if (length(x) >1) {
        for (i in seq(2, length(x), by=1)) {
            x[[i]] <- strata(x[,i-1], x[i], shortlabel=TRUE, sep='/')
            }
       } 
    x
    }
@     

Creation of the $C$ matrix is just a bit more work.  
One issue is that none of the standard S contrast options is correct.
With a Gaussian random effect, either a random intercept or a random slope,  
the proper constraint is $b' \Sigma =0$;
this is familiar from older statistics textbooks for ANOVA as the ``sum 
constraint''. 
For a random effect this constraint is automatically enforced by the 
penalized optimization, so the proper coding of a factor with $k$ levels
is as $k$ indicator variables.
We do this by imposing our own contrasts. 
The formula inherited from [[formula2]] already has any intercept removed.
<<get-cmat>>=
getcmat <- function(x, mf) {
    if (is.null(x)) return(NULL)
    varname <- allnames(x)
    m2 <-  mf[,varname]
    for (i in 1:ncol(m2)) {
        if (is.factor(m2[[i]])) {
            nlev <- length(levels(m2[[i]]))
            contrasts(m2[[i]], nlev) <- diag(nlev)
            }
        }
    model.matrix(terms(x), m2)
    }
@ 

The $C$ matrix is crossed with the random effects to get the $Z$
matrix $Z=(C_{11}, C_{2}, \ldots, C_{21}, \ldots)$,
where $C_{ij}$ is [[cmat * (fmt[,i]==j])]]. 
If $F$ has multiple columns and/or any one of the columns has a lot of 
levels then $Z$ can get very large.  
Additionally, if $Z$ has $p$ columns then the Hessian matrix 
for the corresponding
parameters is $p$ by $p$.  
This is an area where the code could use more sparse matrix intelligence, i.e.,
so that the expanded $Z$ need never be created.

<<newzmat>>=
newzmat <- function(cmat, fmat) {
    newcol <- ncol(cmat) * sum(apply(fmat,2,max))
    newz <- matrix(0., nrow=nrow(cmat), ncol=newcol)
    indx <- 0
    nc <- ncol(cmat)
    for (i in 1:ncol(fmat)){
        for (j in 1:max(fmat[,i])) {
            newz[, 1:nc + indx] <- cmat * (fmat[,i]==j)
            indx <- indx + nc
            }
        }
    newz
    }
@ 
