\section{Variance families}
\subsection{Structure}
Each distinct random effects term corresponds to a distinct
diagonal block in the overall penalty matrix, along with a
set of penalized coefficients $b$.
To make life easier for the maximizer, there may also
be a transformation between the displayed variance 
coefficients and the internal ones.
When there are multiple random terms in the formula then the
[[varfun]], [[vinit]], and [[variance]] arguments must each be in
the form of a list with one element per random term. 

The variance family objects for [[coxme]] are similar in spirit to [[glm]]
families: the functions set up the structure but do not do any
work.  
Each of them returns a list of 3 functions, [[initialize]], [[generate]], and
[[wrapup]].
Any optional arguments to the variance family are used to create these
three; depending on the family they might apply to any one.

The initialize function is called with the $Z$ and $G$ matrices for the
given term, along with the sparse option and 
the appropriate vectors of initial and fixed values.

The return from a call to initialize is
\begin{description}
\item[theta] a vector of initial values for all the parameters
that need to be optimized.  This implicitly gives the number
of parameters to optimize.
\item[X] the design matrix for any random slopes
\item[G] the design matrix for any random factors
\item[parm] a list of arguments to be passed forward to the 
generate and wrapup functions. 
\item[error] optional error message.  This is passed up so the parent
  can print an error message with more information.
\end{description}

The $G$ matrix passed in and the $F$ matrix returned may not be the same.
In particular, any class levels that are going to be treated as
sparse will have been rearranged to so as to be the first columns of
the penalty matrix (variance of the random effect), and so will have
level indices of 1,2, \ldots.

The \emph{generate} function is called at each iteration with the current
vector of parameters $\theta$ and the parameter list.  It will generate
the variance matrix of the random effect. 
If there are multiple random effect terms, each of the generate
functions creates the appropriate block.

The \emph{wrapup} function is called when iteration is complete.  Its
primary job is to return the extended and re-transformed $\theta$
vector.  Fixed coefficients are re-inserted.

For both initial values and fixed values we try to be as forgiving
as possible, by first matching on names and then matching any
unnamed arguments.
Say for instance that the the term is [[(1| race/sex)]], then all of
\begin{itemize}
  \item [[vinit = list(1,2)]]
  \item [[vinit = list(sex=2)]]
  \item [[vinit = list(sex=2, 1)]]
  \item [[vinit = c(sex=2, 1)]]
\end{itemize}
are legal.  We do this by augmenting pmatch to add in unnamed args.
The return is a vector of integers of the same length as init showing
which term they match to.
So [[vinit=1:3]] would return $(1,2,0)$ and
[[vinit=c(sex=2, school=3)]] would give $(2,0)$.
<<initmatch>>=
initmatch <- function(namelist, init) {
    if (is.null(names(init))) iname <- rep('', length(init))
    else iname <- names(init)
    
    indx1 <- pmatch(iname, namelist, nomatch=0, duplicates.ok=TRUE)
    if (any(iname=='')) {
        temp <- 1:length(namelist)
        if (any(indx1>0)) temp <- temp[-indx1]   #already used
        indx2 <- which(iname=='')
        n <- min(length(indx2), length(temp))
        if (n>0) indx1[indx2[1:n]] <- temp[1:n]
        }
    indx1
    }
@ 

\subsection{Sparseness}

This is a good point to remind myself of an important distinction.
When fitting the Cox likelihood we have to be aware of which terms of the
partial likelihood's hessian matrix (second derivative) can be      %'
considered ``sparse'' or not.  Because the C code expects the Hessian and the
penalty to have exactly the same bdsmatrix form, the [[kfun]] function
in [[coxme.fit]] has to orchestrate which parts of the penalty 
can be represented using
the sparse part of a bdsmatrix (the blocks and blocksize components) and
which has to use the dense part (the rmat component).  
Essentially, it treats terms 2, 3, \ldots as dense, and for the first
term it \emph{believes what the variance function sends it}.
Thus, this is the point at which ``sparseness'' is determined.

A \emph{b}lock \emph{d}iagonal \emph{s}ymmetric [[bdsmatrix]] object 
consists of two portions: a block diagonal section in the upper left and
a dense border.  Since it is symmetric only the right hand border is
retained.
If the block diagonal section has only a single block, then the matrix
is dense; if there are many blocks it will be sparse.

Although the variance matrices themselves are often very sparse, in
particular multiple random terms are independent, the Cox model's
Hessian matrix is never sparse.  What we have found is that for some
cases, one can pretend the Hessian is sparse.  They are captured below.

\subsection{coxvarFull}
This is the default routine, which assumes a simple nested structure
for the variance.
Sparsity is assumed only for random intercepts, for those groups which
have a small percent of the total.

To describe the layout, we consider four cases of increasing complexity.
The first case is a simple random grouping effect [[(1|g1)]]. 
The input will have $G$ as a single column data frame containing a single
grouping variable, often represented as a factor and  $Z$ will be null.
If $G$ has $g$ levels, then the vector of random intercepts will be of
length $g$, there is a single random variance, and
$$
b_i \sim N(0, \sigma^2 I)
$$


The input data [[G]] is a data frame with one variable per level of
nesting.  We start by processing the initial value and fixed variance
arguments, which in the intercept case match the names of the nesting
variables.  Definition of the two other cases for initial values are
deferred until later.

<<coxvarFull>>=
coxvarFull <- function(collapse=TRUE) {
    collapse <- collapse
    # Because of R's lexical scoping, the values of the options
    #  above, at the time the line below is run, are known to the
    #  initialize function
    <<coxvarFull-init>>
    <<coxvarFull-generate>>
    <<coxvarFull-wrapup>>
    out <- list(initialize=initialize, generate=generate, wrapup=wrapup)
    oldClass(out) <- 'coxvar'
    out
    }
@ 

<<coxvarFull-init>>= 
    initialize <- function(initial, fixed, intercept, G, Z,  sparse) {
        <<initmatch>>
        if (is.null(Z)) nvar <- 0
	else nvar <- ncol(Z)

        if (nvar==0 & is.null(G))
            return(list(error=("Invalid null random term (1|1)")))

	# Initial values
        if (intercept && nvar==0) {
	    gname <- names(G)
	    ntheta <- length(gname)
	    theta <- rep(.2, ntheta)
            if (length(initial) >0) {
                temp <- initmatch(gname, initial)
	        if (any(temp==0))
		    return(list(error=paste('Element', which(temp==0),
                                            'of initial values not matched')))
                else theta[temp] <- unlist(initial)
		if (any(theta <=0))
                    return(list(error='Invalid initial value'))
		}

            which.fixed <- rep(FALSE, ntheta)
            if (length(fixed)>0) {
	        temp <- initmatch(gname, fixed)
	        if (any(temp==0))
		    return(list(error=paste('Element', which(temp==0),
                                            'of variance values not matched')))
                else theta[temp] <- unlist(fixed)
		which.fixed[temp] <- TRUE
		}
            }
        else if (nvar>0 & !intercept) {
	  <<set-initial-2>>
	  }
	else {
	  <<set-initial-3>>
              }
              
        # The 5 cases
        if (intercept && nvar==0) {
            if (ncol(G)==1) {
                <<coxvarFull-init1>>  
                }
            else {
                <<coxvarFull-init2>>
                <<coxvarFull-init3>>
                }
            }
        else if (!intercept) {
            <<coxvarFull-init4>>
            }
        else {
            <<coxvarFull-init5>>
                }
        }
@ 

Case 1 is the simplest one of a single grouping variable and
no covariates. If sparseness
applies, then the levels of the variable are reordered to put the
infrequent levels first, and the variance matrix starts with
nsparse $1\times 1$ blocks.
<<coxvarFull-init1>>=
    gtemp <- as.factor(G[[1]])[,drop=TRUE] #drop unused levels
    nlevel <- length(levels(gtemp))
    gfrac <- table(gtemp)/ length(gtemp)
    if (nlevel > sparse[1] && any(gfrac <= sparse[2])) {
        indx <- order((gfrac<= sparse[2]), 1:nlevel)
        gtemp <- factor(gtemp, levels=levels(gtemp)[indx])
        nsparse <- sum(gfrac <= sparse[2])
        if (nsparse== nlevel) vmat<- bdsI(nsparse)
        else {
            k <- nlevel - nsparse  #number of non-sparse levels
            rmat <- matrix(0., nrow=nlevel, ncol=k)
            rmat[1:k + nsparse, 1:k] <- 1.0
            vmat <- bdsmatrix(blocksize=rep(1,nsparse), 
                               blocks= rep(1,nsparse), rmat=rmat)
            }
        }
    else vmat <- diag(nlevel)
    
    list(F=matrix(as.numeric(gtemp)), X=NULL, 
         theta=log(theta[!which.fixed]), 
         levels=levels(gtemp),
         parms=list(vmat=vmat, theta=theta, level=levels(gtemp),
                    fixed=which.fixed, case=1))

@	    

The generate function for this first case is quite simple.
<<coxvarFull-generate>>=
   generate= function(newtheta, parms) {
       theta <- parms$theta
       if (length(newtheta)>0) theta[!parms$fixed] <- exp(newtheta)
       switch(parms$case,
           theta * parms$vmat,
           
       
@ 


The second case is an intercept with nested grouping variables.
We first expand out the second variable; for a term such as
[[(1 | school/teacher)]] we need to relabel the [[teacher]] variable
so that teacher 1 in school A is different than teacher 1 in school
B.
This will lead to a stucture with $g_1$ levels for the first variable
$g_1*g_2$ levels for the second, and so on. 
The simplest way to set this up is to create two columns in $F$, one
for each variable, corresponding to the following structure.
\begin{eqnarray*}
 b_i &\sim & N(0, \sigma_1^2 I) \\
 c_{ij} &\sim & N(0, \sigma_2^2 I)\\
\end{eqnarray*}
Sparseness is applied to the \emph{last} variable in the nesting, since
it has the largest number of levels.
This ends up reversing the parameters, which we will undo later in the
wrapup function.

<<coxvarFull-init2>>=
    G <- expand.nested(G)
    if (!collapse) {
        n.nest <- ncol(G)
        F <- matrix(0, nrow=nrow(G), ncol=n.nest)
        nlevel <- sapply(G, function(x) length(levels(x)))
        levellist <- vector('list', n.nest)
        vars <- vector('list', n.nest)
        
        # last first
        gtemp <- as.factor(G[n.nest])[,drop=TRUE]
        gfrac <- table(gtemp)/ length(gtemp)
        if (nlevel[ncol(G)] > sparse[1] && any(gfrac <= sparse[2])) {
            indx <- order((gfrac<= sparse[2]), 1:nlevel)
            gtemp <- factor(gtemp, levels=levels(gtemp)[indx])
            nsparse <- sum(gfrac <= sparse[2])
            }
        else nsparse <- 0
        F[,1] <- as.integer(gtemp) 
        levellist[[1]] <- levels(gtemp)
        
        for (i in 2:n.nest) {
            j <- 1 + n.nest -i
            F[,i] <- as.numeric(G[,j])
            levellist[[i]] <- levels(G[,j])
            }
 
        list(F=F, X=NULL, 
    	     theta=log(theta[!which.fixed]),
    	     parms=list(nlevel=rev(nlevel), nsparse=nsparse, 
                        fixed=which.fixed, levels=levellist, case=2))
        }
@ 

All of the variance parameters are independent, so the generate function
needs to create a diagonal matrix, as either a matrix or bdsmatrix 
(if nsparse>0) or matrix object.

<<coxvarFull-generate>>= 
    {if (parms$nsparse >0) {
        temp <- nlevel
        temp[1] <- temp[1] - nsparse
        bdsmatrix(blocksize=rep(1, nsparse), blocks=rep(1., nsparse),
                  rmat=rbind(matrix(0.,nrow=nsparse, ncol=sum(nlevel)),
                             diag(rep(theta, temp))))
        }
     else diag(rep(theta, parms$nlevel))
     },
@    

Although the above is a simple approach, we have found the program 
is often much more stable using an alternate
representation. 
I hypothesise that this is due to a smaller number of nuisance
variables.  Let
\begin{eqnarray*}
 d_{ij}&=& b_i + c_{ij} \\
 d &\sim& N(0, A) \\
\end{eqnarray*}
where $A$ is a block diagonal array with one block for each level
of the primary grouping variable$b$, and
\begin{eqnarray*}
  A_{ii} &=& \sigma_1^2 + \sigma_2^2\\
  A_{ij} &=& \sigma_1^2
\end{eqnarray*}
for $i$ and $j$ in the same block, and 0 otherwise.
The size of the first block is the number of unique levels of $c$ that
occur for the first level of $b$.
We can treat the fit as a single random effect $d$, but with a more
complex variance/covariance matrix between the terms.
What constitutes ``sufficient'' sparseness is not as clear in this
case. I have not convinced myself that any route is safe and so we
do not attempt it.

Here is the
code, which is fairly simple.
The last loop helps computational speed, in a somewhat non-obvious
way.  The [[generate]] routine below will add up these matrices.  That
process goes much faster when they all conform exactly.  Because of
their structure these matrices can be made to conform: adding 0 forces
them to do so at this point rather than waiting till later additions.
<<coxvarFull-init3>>=
  else { #ncol(G)>1, intercept=T, nvar=0, collapse=T
      varlist <- vector('list', ncol(G))
      ulist <- G[,ncol(G)]
      for (i in 1:(ncol(G)-1)) {
          bsize <- tapply(ulist, G[,i], function(x) length(unique(x)))
          varlist[[i]] <- bdsmatrix(blocksize=bsize,
                                    blocks=rep(1., sum((bsize*(bsize+1))/2)))
          }
      varlist[ncol(G)] <- bdsI(length(unique(ulist))) 
      for (i in 2:ncol(G)) varlist[[i]] <- varlist[[i]] + 0*varlist[[1]]
      
      list(F=as.numeric(ulist), X=NULL, 
           theta=log(theta[!which.fixed]),
           parms=list(varlist=varlist, theta=theta, 
                      fixed=which.fixed,
                      levels=lapply(G, function(x) levels(x)), case=3))
      }
@ 

The generation routine is simple.  Although all of our arithmetic is done
with [[bdsmatrix]] objects for speed and size, the result is a matrix
so as not to imply sparseness.
<<coxvarFull-generate>>=
       {temp <- parms$varlist[[1]] * theta[1]
        for (i in 2:length(theta))
            temp <- temp + parms$varlist[[i]] * theta[i]
        as.matrix(temp)},
@ 



The next case to process is a shrinkage term such as 
[[(x1 + x2 | 1)]].
In this case the two coefficients for [[x1]] and [[x2]] are considered
to come from a Gaussian with a common variance $\sigma^2$.
If the variance is fixed, this is equivalent to ordinary ridge
regression.
<<set-initial-2>>=
    if (length(initial) >0) {
        if (length(initial)==1) theta <- as.numreric(initial)
        else return(list(error="Initial value should have length 1"))
        }
    else theta=.2
    
    if (length(variance) >0) {
        if (length(variance)==1) {
            which.fixed <- TRUE
            theta <- variance
            }
        else return(list(error="Fixed variance should have a length of 1"))
        }
    else which.fixed <- FALSE
@ 

<<coxvarFull-init4>>=
#case 4
if (nvar >0 && is.null(G)) {
   list(theta=theta[!which.fixed], F=NULL, X=Z,
         parms=list(which.fixed=which.fixed, theta=theta, nvar=nvar,
                    case=4))
    }
@ 

<<coxvarFull-generate>>=
        diag(nvar) * theta,
@ 


The last case is the hardest; we have both grouping factors and
covariates.
Consider the simplest case of [[(1+age) | grp)]].
The matrix $F$ and its sparsity is handled with the same logic as
found above.  (We currently ignore the collapse argument).
<<coxvarFull-init5>>=
    if (ncol(G)==1) {
        gtemp <- as.factor(G[[1]])[,drop=TRUE] #drop unused levels
        nlevel <- length(levels(gtemp))
        gfrac <- table(gtemp)/ length(gtemp)
        if (nlevel > sparse[1] && any(gfrac <= sparse[2])) {
            indx <- order((gfrac<= sparse[2]), 1:nlevel)
            gtemp <- factor(gtemp, levels=levels(gtemp)[order(gfad)])
            nsparse <- sum(gfrac <= sparse[2])
            }
        else nsparse=0 
        F <- as.numeric(gtemp)
        
@ 
The returned $X$ matrix, however, will have one regression column for
the covariate [[age]] for each level of the grouping variable.  
In general it has ngroup colums
for the first covariate, then ngroup for the second, etc.
Since in this structure the coefficients for someone in group 1 will
be in position 1, 1+ngroup, 1+ 2*ngroup, \ldots, the variance matrix
will be a set of blocks.  
If there were two variables the matrix would be
$$
\left( \begin{array}{ccc}
  \sigma^2_1 I & \sigma_{12} I & \sigma_{13}I \\
  \sigma_{12}I & \sigma_2^2 I &  \sigma_{23}I \\
  \sigma_{13}I & \sigma_{23}I &  \sigma_3^2 \end{array} \right)
$$
where each of the identity matrices $I$ is of dimension ngroup.
<<coxvarFull-init5>>=
        ngroup <- length(levels(gtemp))
        X <- matrix(0., nrow=length(gtemp), ncol=ngroup*nvar)
        indx <- seq(0, length=nvar, by=ngroup)
        for (i in 1:ngroup) 
            X[,i+indx] <- Z * (F==i)
                    
        list(theta=theta[!fixed], F=F, X=X, 
             parms=list(theta[!which.fixed], which.fixed=which.fixed,
                        nvar=nvar, ngroup=ngroup, case=5))
        }
    else stop("Case not yet coded")
@                 

The generation routine only needs to fill in above the diagonal.
It will use a bdsmatrix with the first block for intercept terms (so that
sparseness is handled correctly).
The parameter vector is stored as a set of transformed standard deviations
and correlations.
<<coxvarFull-generate>>=
    {ngroup <- parms$ngroup
    nvar <- parms$nvar

    vmat <- diag(nvar+1)  #variance matrix = transformed parameters
    k <- nvar+2
    temp <- exp(parms)            
    for (i in 1:nvar) {
        for (j in (i+1):(nvar+1)) {
            cmat[i,j] <- (temp[k] -1) /(temp[k] +1)
            k <- k+1
            }
        vmat[i,] <- vmat[i,] * temp[i]
        vmat[,i] <- vmat[,i] * temp[i]
        }   
    
    
    rtemp <- matrix(0., nrow=ngroup * (nvar+1),
                        ncol=ngroup * (nvar+1))
    indx1 <- seq(1, by=nrow(rtemp)+1, length=ngroup)
    for (i in 1:(nvar+1)) {
        for (j in i:(nvar+1)) {
            indx2 <- (i-1)*ngroup + (j-1)*nrow(rtemp)
            rtemp[indx1+indx2] <- vmat[i,j]
            }
        }
    bdsmatrix(blocksize=ngroup, blocks=rep(vmat[1,1], ngroup),
              rmat=rtemp[,-(1:ngroup)])
    })
}
@ 

Finally, here is the initialiation code for this last case.
<<set-initial-3>>=
if (ncol(G) > 1) 
    return(list(error="Not yet written- nested groups + random slopes"))
ngroup <- length(unique(G))
theta <- c(rep(.44, nvar+1), rep(0., nvar*(nvar+1)/2))
@ 
  

The wrapup function transforms theta back, and adds names.
<<coxvarFull-wrapup>>=
wrapup <- function(theta, parms) {
    newtheta <- parms$theta
    newtheta[!parms$fixed] <- exp(theta)
    
    if (parms$case == 5)  # correlations
        newtheta=newtheta
    newtheta
    }
@ 
    
\subsection{coxvarMlist}
In a mixed-effects model the random effects $b$ are assumed to
follow a Gaussian distribution
$$
  b \sim N(0, \Sigma)
$$
In all the random effects modeling programs that I am aware of,
the user specifies the structure of $\Sigma$ and the program
constructs the actual matrix.  
For instance, `independent', `compound symmetry', or `autoregressive'.
This basic approach does not work for genetic studies, since the
correlation is based on family structure and cannot be inferred from
a simple keyword.
The [[coxvarMlist]] variance specification accepts a list of
fixed matrices $A_1$, $A_2$, ... and fits the variance
structure $\Sigma = \sigma_1^2 A_1 + \sigma_2^2 A_2 + \ldots$.
The individual matrices are often in a block-diagonal sparse 
representation due to size.
(The motivating study for this structure had 26050 subjects with a
random intercept per subject, so that $A$ was 26050 by 26050.)

The matrices must have dimnames that match the levels of the 
grouping variable.  Much of the initialization work is to verify
this, remove unneeded columns of the matrices (if for instance a
subject has been dropped due to missing values), and reorder the
grouping variable to match the resulting matrix. ( Sparse matrices
cannot be arbitrarily reordered, so whatever label is on row 1 of the
variance matrix needs to become the first level of the grouping
variable, the second row the second, etc, during the computations.)
Much of this low level work is done by the [[coxme.varcheck]] routine.

Three checks on the matrices are commonly added.  
\begin{enumerate}
\item A solution with $A^*= A/2$ and $\sigma^* = \sigma \sqrt{2}$ is
of course equivalent to one with $A$ and $\sigma$.
For uniqueness, the matrices $A_1$, $A_2$ etc are rescaled to have a
diagonal of 1.  Kinship matrices in particular have a diagonal of 1/2.
\item The individual $A$ matrices are checked to verify that each is
positive definite.  If they are not this is most often reflects an 
error in forming them.
\item The parameters $\sigma$ are constrained to be $>0$.
\end{enumerate}
%I have had one problem where the first two had to be relaxed: to understand
%the interaction of gender and inheritance in breast/prostate cancer,
%we wanted to fit a model with the $n$ by $n$ kinship matrix $K$ as the
% correlation, but
%with separate scaling factors for male/male, male/female, and female/female
%pairs of subjects.
%This is easily done by a separation $K = K_{mm} + K_{ff} + K_{mf}$,
%where the $K_{mm}$ matrix for instance has zeros for all male/female and
%female/female elements.
%The $K_{mf}$ matrix has zero on the diagonal, so cannot be rescaled nor is
%it positive definite.

<<coxvarMlist>>=
coxvarMlist <- function(..., rescale=TRUE, pdcheck=TRUE,  positive=NULL) {
    varlist <- list(...)
    # Because of environments, the init function will inherit the
    #  three variables below
    rescale <- rescale
    pdcheck <- pdcheck
    positive <- positive
    
    initialize <- function(initial, fixed, intercept, G, Z, sparse) {
        ncluster <- length(G)
        if (ncluster==0) stop ("Mlist variance requires a grouping variable")
        if (length(Z)>0) stop ("Mlist variance does not allow random slopes")
        if (!intercept)  stop ("Mlist variance applies only to intercepts")

        groups <- expand.nested(G)
        temp <- coxme.varcheck(ncluster, varlist, n=length(G[[1]]),
                               gvars= names(G), 
                               groups= groups[[ncluster]], sparse,
                               rescale, pdcheck)
        ntheta <- temp$ntheta
        theta <- seq(.2, .3, length=ntheta) 
        if (length(initial)>0) {
            if (length(initial) != ntheta) 
                return(list(error="Wrong length for initial vector"))
            theta <- initial
            }
        if (length(fixed) >0) {
            if (length(fixed) != ntheta)
                return(list(error="Wrong length for fixed values"))
            which.fixed <- (!(is.na(fixed) | fixed==0))
            }
        else which.fixed <- rep(FALSE, ntheta)

        if (is.null(positive)) positive <- rep(TRUE, ntheta)
        else {
            if (!is.logical(positive))
                return(list(
                       error="Positivity constraint must be a logical vector"))
            if (length(positive) != ntheta) 
                return(list(error="Wrong length for positivity constraint"))
            }
        if (any(positive & theta <=0))
            return(list(error="Invalid initial value, must be positive"))        
        theta[positive] <- log(theta[positive])

        list(F=temp$kindex, X=NULL, theta=theta[!which.fixed],
             parms=list(varlist =temp$varlist, theta=theta,
                        fixed=which.fixed, positive=positive))
        }
    
     generate <- function(newtheta, parms) {
         theta <- parms$theta
         theta[!parms$fixed] <- newtheta
         theta[parms$positive] <- exp(theta[parms$positive])
         
         varmat <- parms$varlist[[1]] * theta[1]
         if (length(theta) >1) {
             for (i in 2:length(theta)) {
                 varmat <- varmat + theta[i]*parms$varlist[[i]]
                 }
             }
         varmat
         }

    wrapup <- function(newtheta,parms) {
        theta <- parms$theta
        theta[!parms.fixed] <- newtheta
        theta[parms$positive] <- exp(theta[parms$positive])
        theta
        }
    
    out <- list(initialize=initialize, generate=generate, wrapup=wrapup)
    oldClass(out) <- 'coxvar'
    out
    }
@ 
